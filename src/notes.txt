Use scrapy framework to scrape the first 500 items (title, image url) from sreality.cz (flats, sell) and save it in the Postgresql database. Implement a simple HTTP server in python and show these 500 items on a simple page (title and image) and put everything to single docker compose command so that I can just run "docker-compose up" in the Github repository and see the scraped ads on http://127.0.0.1:8080 page.


scrapy shell https://www.sreality.cz/hledani/prodej/byty?_escaped_fragment_=
This is needed to access the page with results

https://www.sreality.cz/hledani/prodej/byty?strana=3
This takes me to other pages - do that 25 times? That seems stupid but could work

response.css('div._15Md1MuBeW62jbm5iL0XqR > div > a > img::attr(src)').getall()
This gets all images from the divs with the correct class - the images of flats

Rest of docker-compose
  web:
    build: .
    command: python main.py
    volumes:
      - .:/code
    ports:
      - "8080:8080"
    depends_on:
      - db
